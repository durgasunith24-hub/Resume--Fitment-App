{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "# Connect to the database\n",
        "db_path = '/content/sample_data/Blooms.db'\n",
        "conn = sqlite3.connect(db_path)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Get list of tables\n",
        "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "tables = [row[0] for row in cursor.fetchall()]\n",
        "\n",
        "print(\"Table Summary (One row per table):\\n\")\n",
        "print(f\"{'Table Name':<12} | {'Row Count':<10} | Columns\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# For each table, get column names and row count\n",
        "for table in tables:\n",
        "    # Get row count\n",
        "    cursor.execute(f\"SELECT COUNT(*) FROM {table}\")\n",
        "    row_count = cursor.fetchone()[0]\n",
        "\n",
        "    # Get column names\n",
        "    cursor.execute(f\"PRAGMA table_info({table});\")\n",
        "    columns = [col[1] for col in cursor.fetchall()]\n",
        "    column_str = ', '.join(columns)\n",
        "\n",
        "    # Display in row\n",
        "    print(f\"{table:<12} | {row_count:<10} | {column_str}\")\n",
        "\n",
        "# Close connection\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "actsPhXT70rY",
        "outputId": "6f1faf51-b104-4a46-d500-3e6dfd48d4f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Table Summary (One row per table):\n",
            "\n",
            "Table Name   | Row Count  | Columns\n",
            "--------------------------------------------------------------------------------\n",
            "FlanCSV      | 100        | resume_path, person_name, current_role, total_experience, current_tenure, certification_count, publication_count, skill_density\n",
            "GPTCSV       | 100        | resume_path, person_name, current_role, total_experience, current_tenure, certification_count, publication_count, skill_density\n",
            "LLamaCSV     | 100        | resume_path, person_name, current_role, total_experience, current_tenure, certification_count, publication_count, skill_density\n",
            "NLPCSV       | 100        | resume_path, person_name, current_role, total_experience, current_tenure, certification_count, publication_count, skill_density\n",
            "GTCSV        | 100        | resume_path, person_name, current_role, total_experience, current_tenure, certification_count, publication_count, skill_density\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKoriAao0THT",
        "outputId": "5516b59a-68fb-4c62-cb16-9a680fca162c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step1_upload_and_extract_jd.py\n",
        "from docx import Document\n",
        "import os\n",
        "\n",
        "def extract_text_from_docx(file_path):\n",
        "    doc = Document(file_path)\n",
        "    return \"\\n\".join([p.text.strip() for p in doc.paragraphs if p.text.strip()])\n",
        "\n",
        "# Ask user to upload\n",
        "jd_file_path = input(\"ðŸ“‚ Enter full path to your JD (.docx) file: \").strip()\n",
        "\n",
        "if not os.path.exists(jd_file_path):\n",
        "    print(\"âŒ File does not exist. Exiting.\")\n",
        "    exit()\n",
        "\n",
        "jd_text = extract_text_from_docx(jd_file_path)\n",
        "print(\"\\nðŸ“„ Extracted JD Text:\\n\")\n",
        "print(jd_text[:1000] + \"\\n...\" if len(jd_text) > 1000 else jd_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-0ZBdfSxVuc",
        "outputId": "9a639e91-f816-48a8-9d09-ebe4531b8593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“‚ Enter full path to your JD (.docx) file: /content/sample_data/Business Development Executive.docx\n",
            "\n",
            "ðŸ“„ Extracted JD Text:\n",
            "\n",
            "Business Development Executive\n",
            "About the Position\n",
            "We are seeking proactive and driven Business Development Executives to join our admissions team. This role is instrumental in promoting our specialized Postgraduate, Masterâ€™s, and Executive Certification Programs designed for working professionals across industries. You will work alongside the Business Development Manager to generate leads, engage with prospective learners, and drive admissions conversions.\n",
            "Job Role and Responsibilities\n",
            "Proactively identify and engage potential candidates via inbound/outbound calls, cold calling, and email campaigns\n",
            "Qualify leads based on eligibility and interest, and collaborate with the Business Development Manager for timely follow-ups and conversions\n",
            "Recommend suitable programs to prospective learners based on their professional background and career goals\n",
            "Maintain detailed and up-to-date records of all interactions and lead progress using the CRM system\n",
            "Ensure a minimum of 180 minutes of daily talk\n",
            "...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step2_extract_jd_features_manual.py\n",
        "import re\n",
        "\n",
        "def basic_feature_extraction(jd_text):\n",
        "    jd_text_lower = jd_text.lower()\n",
        "\n",
        "    # Basic heuristics (adjust if needed)\n",
        "    experience = int(re.search(r'(\\d+)\\+?\\s+years? of experience', jd_text_lower).group(1)) if re.search(r'(\\d+)\\+?\\s+years? of experience', jd_text_lower) else 1\n",
        "    tenure = 1  # Assume 1 year if not found\n",
        "    certification = jd_text_lower.count(\"certification\")\n",
        "    publication = jd_text_lower.count(\"publication\") + jd_text_lower.count(\"research paper\")\n",
        "    skill_keywords = [\"python\", \"sql\", \"excel\", \"communication\", \"leadership\", \"project management\", \"data analysis\"]\n",
        "    skill_density = sum(1 for skill in skill_keywords if skill in jd_text_lower)\n",
        "\n",
        "    return {\n",
        "        \"experience\": experience,\n",
        "        \"tenure\": tenure,\n",
        "        \"certification\": certification,\n",
        "        \"publication\": publication,\n",
        "        \"skill_density\": skill_density\n",
        "    }\n",
        "\n",
        "# === Run this after extracting jd_text in Step 1\n",
        "jd_features = basic_feature_extraction(jd_text)\n",
        "\n",
        "print(\"\\nâœ… Extracted JD Features:\")\n",
        "for k, v in jd_features.items():\n",
        "    print(f\"{k:<15}: {v}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2HwhLge011j",
        "outputId": "aed72634-6290-4586-8312-692ea568d653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Extracted JD Features:\n",
            "experience     : 1\n",
            "tenure         : 1\n",
            "certification  : 1\n",
            "publication    : 0\n",
            "skill_density  : 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step3_normalize_weights.py\n",
        "\n",
        "def normalize_weights(jd_features):\n",
        "    total = sum(jd_features.values())\n",
        "    if total == 0:\n",
        "        print(\"âŒ All feature values are zero. Cannot normalize.\")\n",
        "        return {k: 0 for k in jd_features}\n",
        "    return {k: v / total for k, v in jd_features.items()}\n",
        "\n",
        "jd_weights = normalize_weights(jd_features)\n",
        "\n",
        "print(\"\\nðŸ“Š Normalized JD Weights:\")\n",
        "for k, v in jd_weights.items():\n",
        "    print(f\"{k:<15}: {v:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzkoOrkN07o8",
        "outputId": "a46d726d-7e8a-43ca-d286-3f49c1fb9427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Normalized JD Weights:\n",
            "experience     : 0.200\n",
            "tenure         : 0.200\n",
            "certification  : 0.200\n",
            "publication    : 0.000\n",
            "skill_density  : 0.400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step4_compute_fitment.py\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "DB_PATH = r\"/content/sample_data/Blooms.db\"  # âœ… Update path if needed\n",
        "OUTPUT_DIR = \"/content/sample_data/fitment_reports\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "model_tables = [\"FlanCSV\", \"GPTCSV\", \"LLamaCSV\", \"NLPCSV\", \"GTCSV\"]\n",
        "\n",
        "def compute_score(row, weights):\n",
        "    return round(\n",
        "        row.get(\"skill_density\", 0) * weights.get(\"skill_density\", 0) +\n",
        "        row.get(\"total_experience\", 0) * weights.get(\"experience\", 0) +\n",
        "        row.get(\"current_tenure\", 0) * weights.get(\"tenure\", 0) +\n",
        "        row.get(\"certification_count\", 0) * weights.get(\"certification\", 0) +\n",
        "        row.get(\"publication_count\", 0) * weights.get(\"publication\", 0),\n",
        "        2\n",
        "    )\n",
        "\n",
        "def classify_fit(score_pct):\n",
        "    if score_pct < 31:\n",
        "        return \"Low Fit\"\n",
        "    elif score_pct < 71:\n",
        "        return \"Medium Fit\"\n",
        "    else:\n",
        "        return \"Fit\"\n",
        "\n",
        "def process_table(table, conn, weights):\n",
        "    df = pd.read_sql_query(f\"SELECT * FROM {table}\", conn)\n",
        "\n",
        "    required = {\n",
        "        \"resume_path\", \"person_name\", \"total_experience\", \"current_tenure\",\n",
        "        \"certification_count\", \"publication_count\", \"skill_density\"\n",
        "    }\n",
        "\n",
        "    if not required.issubset(df.columns):\n",
        "        print(f\"âš ï¸ Skipping {table} â€” missing required columns.\")\n",
        "        return\n",
        "\n",
        "    # Compute raw and normalized score\n",
        "    df[\"raw_score\"] = df.apply(lambda row: compute_score(row, weights), axis=1)\n",
        "    max_score = df[\"raw_score\"].max() or 1\n",
        "    df[\"fitment_score\"] = (df[\"raw_score\"] / max_score * 100).round(2)\n",
        "    df[\"fitment_level\"] = df[\"fitment_score\"].apply(classify_fit)\n",
        "\n",
        "    # Save final 4-column report\n",
        "    out_df = df[[\"resume_path\", \"person_name\", \"fitment_level\", \"fitment_score\"]]\n",
        "    out_file = os.path.join(OUTPUT_DIR, f\"{table}_fitment.csv\")\n",
        "    out_df.to_csv(out_file, index=False)\n",
        "    print(f\"âœ… Saved: {out_file}\")\n",
        "\n",
        "# === Run for all tables ===\n",
        "conn = sqlite3.connect(DB_PATH)\n",
        "print(\"\\nðŸ“Š Computing fitment for all models...\\n\")\n",
        "for table in model_tables:\n",
        "    process_table(table, conn, jd_weights)\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KPJ-3ec1C_1",
        "outputId": "782cb5bc-62d5-4c1e-8c98-08c606f1baad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Computing fitment for all models...\n",
            "\n",
            "âœ… Saved: /content/sample_data/fitment_reports/FlanCSV_fitment.csv\n",
            "âœ… Saved: /content/sample_data/fitment_reports/GPTCSV_fitment.csv\n",
            "âœ… Saved: /content/sample_data/fitment_reports/LLamaCSV_fitment.csv\n",
            "âœ… Saved: /content/sample_data/fitment_reports/NLPCSV_fitment.csv\n",
            "âœ… Saved: /content/sample_data/fitment_reports/GTCSV_fitment.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from functools import reduce\n",
        "\n",
        "FOLDER = \"/content/sample_data/fitment_reports\"\n",
        "tables = {\n",
        "    \"Flan\": \"FlanCSV_fitment.csv\",\n",
        "    \"GPT\": \"GPTCSV_fitment.csv\",\n",
        "    \"LLama\": \"LLamaCSV_fitment.csv\",\n",
        "    \"NLP\": \"NLPCSV_fitment.csv\",\n",
        "    \"GT\": \"GTCSV_fitment.csv\"\n",
        "}\n",
        "\n",
        "dfs = []\n",
        "\n",
        "for model, file in tables.items():\n",
        "    path = os.path.join(FOLDER, file)\n",
        "    if os.path.exists(path):\n",
        "        df = pd.read_csv(path)[[\"resume_path\", \"fitment_score\"]].copy()\n",
        "        df.rename(columns={\"fitment_score\": f\"{model}Score\"}, inplace=True)\n",
        "        dfs.append(df)\n",
        "        print(f\"âœ… Loaded: {file}\")\n",
        "    else:\n",
        "        print(f\"âŒ Missing: {file}\")\n",
        "\n",
        "# Merge all on resume_path\n",
        "if dfs:\n",
        "    merged_df = reduce(lambda left, right: pd.merge(left, right, on=\"resume_path\", how=\"outer\"), dfs)\n",
        "\n",
        "    # Bring in person_name only from GTCSV\n",
        "    gt_path = os.path.join(FOLDER, \"GTCSV_fitment.csv\")\n",
        "    gt_person = pd.read_csv(gt_path)[[\"resume_path\", \"person_name\"]]\n",
        "    merged_df = pd.merge(merged_df, gt_person, on=\"resume_path\", how=\"left\")\n",
        "\n",
        "    # Reorder columns\n",
        "    cols = [\"resume_path\", \"person_name\", \"FlanScore\", \"GPTScore\", \"LLamaScore\", \"NLPScore\", \"GTScore\"]\n",
        "    merged_df = merged_df[[col for col in cols if col in merged_df.columns]]\n",
        "\n",
        "    out_path = os.path.join(FOLDER, \"Combined_Fitment_By_Resume.csv\")\n",
        "    merged_df.to_csv(out_path, index=False)\n",
        "    print(f\"\\nâœ… Combined table saved to:\\n{out_path}\")\n",
        "    print(\"\\nðŸ“Š Sample:\")\n",
        "    print(merged_df.head())\n",
        "else:\n",
        "    print(\"âŒ No fitment files loaded. Check your folder paths.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Da5s26zlOxt",
        "outputId": "b1dc00ad-89b8-4d58-f06a-1269c83af4be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded: FlanCSV_fitment.csv\n",
            "âœ… Loaded: GPTCSV_fitment.csv\n",
            "âœ… Loaded: LLamaCSV_fitment.csv\n",
            "âœ… Loaded: NLPCSV_fitment.csv\n",
            "âœ… Loaded: GTCSV_fitment.csv\n",
            "\n",
            "âœ… Combined table saved to:\n",
            "/content/sample_data/fitment_reports/Combined_Fitment_By_Resume.csv\n",
            "\n",
            "ðŸ“Š Sample:\n",
            "        resume_path      person_name  FlanScore  GPTScore  LLamaScore  \\\n",
            "0    Resume (1).pdf  Swapnil Morande     100.00      13.0        0.00   \n",
            "1   Resume (10).pdf   Kamlesh Sayare      87.88      51.0       56.47   \n",
            "2  Resume (102).pdf   NAVEEN KUMAR N      12.12       8.0        9.41   \n",
            "3  Resume (103).pdf      Parul Runij      33.33       6.0       17.65   \n",
            "4  Resume (105).pdf   Tarumani Raghu      18.18      25.0       14.12   \n",
            "\n",
            "   NLPScore  GTScore  \n",
            "0    100.00   100.00  \n",
            "1     21.93    38.87  \n",
            "2      4.46     8.91  \n",
            "3      8.18    32.39  \n",
            "4      7.81    12.15  \n"
          ]
        }
      ]
    }
  ]
}